{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import efficientnet.tfkeras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 8)\n",
      "Normal:  (115, 8)\n",
      "Abnormal:  (290, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df0 = pd.read_csv (r'/home/yupaporn/codes/USAI/detail1_350_.csv')\n",
    "df01 = df0[(df0['Path Crop']!='None' )&(df0['Path Crop']!='Nan')]\n",
    "a = df01[df01['Case'].between(1, 10)]\n",
    "dataframe = a[a['Abs Position']!='P8']\n",
    "print(dataframe.shape)\n",
    "print('Normal: ',dataframe[dataframe['Class']=='Normal'].shape)\n",
    "print('Abnormal: ',dataframe[dataframe['Class']=='Abnormal'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Case</th>\n",
       "      <th>Abs Position</th>\n",
       "      <th>Sub Position</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sub_class</th>\n",
       "      <th>Path Full</th>\n",
       "      <th>Path Crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>P2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>P3</td>\n",
       "      <td>P31</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>P2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>P5</td>\n",
       "      <td>P51</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>P3</td>\n",
       "      <td>P31</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>AB01</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/ABnormal01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1879</td>\n",
       "      <td>1</td>\n",
       "      <td>P7</td>\n",
       "      <td>P72</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1880</td>\n",
       "      <td>2</td>\n",
       "      <td>P7</td>\n",
       "      <td>P72</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1881</td>\n",
       "      <td>3</td>\n",
       "      <td>P7</td>\n",
       "      <td>P71</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1882</td>\n",
       "      <td>3</td>\n",
       "      <td>P7</td>\n",
       "      <td>P72</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1883</td>\n",
       "      <td>10</td>\n",
       "      <td>P7</td>\n",
       "      <td>P72</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "      <td>/media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Case Abs Position Sub Position     Class Sub_class  \\\n",
       "13            13     3           P2           P2  Abnormal      AB01   \n",
       "15            15     7           P3          P31  Abnormal      AB01   \n",
       "16            16     5           P2           P2  Abnormal      AB01   \n",
       "26            26     9           P5          P51  Abnormal      AB01   \n",
       "29            29     3           P3          P31  Abnormal      AB01   \n",
       "...          ...   ...          ...          ...       ...       ...   \n",
       "1879        1879     1           P7          P72    Normal    Normal   \n",
       "1880        1880     2           P7          P72    Normal    Normal   \n",
       "1881        1881     3           P7          P71    Normal    Normal   \n",
       "1882        1882     3           P7          P72    Normal    Normal   \n",
       "1883        1883    10           P7          P72    Normal    Normal   \n",
       "\n",
       "                                              Path Full  \\\n",
       "13    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "15    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "16    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "26    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "29    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...   \n",
       "...                                                 ...   \n",
       "1879  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...   \n",
       "1880  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...   \n",
       "1881  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...   \n",
       "1882  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...   \n",
       "1883  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...   \n",
       "\n",
       "                                              Path Crop  \n",
       "13    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  \n",
       "15    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  \n",
       "16    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  \n",
       "26    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  \n",
       "29    /media/tohn/HDD/VISION_dataset/USAI/ABnormal01...  \n",
       "...                                                 ...  \n",
       "1879  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...  \n",
       "1880  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...  \n",
       "1881  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...  \n",
       "1882  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...  \n",
       "1883  /media/tohn/HDD/VISION_dataset/USAI/Prelim. Im...  \n",
       "\n",
       "[405 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir ='/media/tohn/SSD/unfreez_model/TrainB0_NA_UnBlock1/models/B0_R1.h5'\n",
    "model = load_model(model_dir)\n",
    "height = width = model.input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "import pandas as pd\n",
    "base_dir  = '/media/tohn/SSD/ImageForTrainTest/validation/'\n",
    "dataframe = pd.read_csv( '/media/tohn/SSD/ImageForTrainTest/validation.csv')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "#Train\n",
    "train_df = pd.read_csv( '/media/tohn/SSD/ImageForTrainTest/train.csv')\n",
    "base_dir0 = '/media/tohn/SSD/ImageForTrainTest/'\n",
    "os.chdir(base_dir0)\n",
    "train_dir = os.path.join(base_dir0, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 405 validated image filenames belonging to 2 classes.\n",
      "{0: 'Abnormal', 1: 'Normal'}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      brightness_range=[0.5,1.5],\n",
    "      shear_range=0.4,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=False,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = train_dir,\n",
    "        x_col = 'Path Crop',\n",
    "        y_col = 'Class',\n",
    "        target_size = (height, width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode= 'rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "#label\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k.replace(\"C\",\"\")) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/tohn/HDD/VISION_dataset/USAI/ABnormal01/1 ABNORMAL/cropped/AB01 P2 C003.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-811951fb5834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Path Crop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprob_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-811951fb5834>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Read the image and resize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Convert it to a Numpy array with target shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/usai/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/tohn/HDD/VISION_dataset/USAI/ABnormal01/1 ABNORMAL/cropped/AB01 P2 C003.JPG'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def predict_image(img_path):\n",
    "    # Read the image and resize it\n",
    "    img = image.load_img(img_path, target_size=(height, width))\n",
    "    # Convert it to a Numpy array with target shape.\n",
    "    x = image.img_to_array(img)\n",
    "    # Reshape\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x /= 255.\n",
    "    result = model.predict([x])\n",
    "    val = -1\n",
    "    idx = -1\n",
    "    \n",
    "    return result[0]\n",
    "\n",
    "#Predict\n",
    "pred_list = list()\n",
    "prob_list = list()\n",
    "img_path=dataframe['Path Crop'].tolist()\n",
    "for i in range(0,len(img_path)):\n",
    "    pred_list.append(labels[np.argmax(predict_image(img_path[i]))])\n",
    "    if np.argmax(predict_image(img_path[i])) == 0:\n",
    "        prob_list.append(predict_image(img_path[i])[0])\n",
    "    else:\n",
    "        prob_list.append(predict_image(img_path[i])[1])\n",
    "        \n",
    "#     print(i)\n",
    "#     print(np.argmax(predict_image(img_path[i])))\n",
    "\n",
    "dataframe['category'] = pred_list\n",
    "dataframe['Prob'] = prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataframe\n",
    "#เช็คคลาสใน Predicted\n",
    "pred_class = set(data_train['category'])\n",
    "print('Predicted : ',len(pred_class))\n",
    "print(pred_class)\n",
    "#เช็คคลาสใน Actual\n",
    "classe = set(data_train['Class'])\n",
    "print('Actual : ',len(classe))\n",
    "print(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "act = data_train['Class'].array\n",
    "pred = data_train['category'].array\n",
    "\n",
    "cmat = confusion_matrix(act, pred)\n",
    "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
    "\n",
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(act, pred))#performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CF \n",
    "data = {'Actual': act,'Predicted' : pred,}\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(act, pred)\n",
    "\n",
    "#plot Confusion matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)\n",
    "ax.set_xlabel('Predicted label',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  confusion_matrix function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_all(data_train,threshold):\n",
    "\n",
    "    #1. manage data  --------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    p1 = data_train #Input table   \n",
    "    act= p1['Class'].map({'Normal':0,'Abnormal':1}).values\n",
    "    pred = p1['category'].map({'Normal':0,'Abnormal':1}).values\n",
    "\n",
    "    import numpy as np\n",
    "    n = len(p1)\n",
    "    proplist = list()\n",
    "    for i in range(0,n):\n",
    "        score = p1.iloc[i].to_numpy()\n",
    "        if score[10]=='Normal':\n",
    "            prob = 1 - score[11]\n",
    "            proplist.append(prob)\n",
    "        else:\n",
    "            prob = score[11]\n",
    "            proplist.append(prob)\n",
    "\n",
    "\n",
    "    prob_all =np.array(proplist)\n",
    "\n",
    "#2. เงื่อนไข ---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix(act, pred).ravel()\n",
    "    print(TN, FP, FN, TP)\n",
    "\n",
    "# 3. threshold ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    t = prob_all >= threshold\n",
    "    #replace\n",
    "    ts =t.tolist()\n",
    "    alist =list()\n",
    "    for i in range(0,len(ts)):\n",
    "        if ts[i]==  True:\n",
    "            a = 1\n",
    "            alist.append(a)\n",
    "        else:\n",
    "            a = 0\n",
    "            alist.append(a)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(act, alist).ravel()\n",
    "\n",
    "    print('(TN,FP,FN,TP)')\n",
    "    print('(',tn,',', fp,',', fn,',', tp,')')\n",
    "    return tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test function\n",
    "threshold = 0.5\n",
    "confusion_matrix_all(data_train,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  run ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "threshold = np.arange(0.0, 1.002, 0.001)\n",
    "precision, recall, ACC, TPR, FPR, SPEC = list(),list(),list(),list(),list(),list()\n",
    "TN0, FP0, FN0, TP0 = list(),list(),list(),list()\n",
    "for i in threshold:\n",
    "    precision0, recall0, ACC0, TPR0, FPR0, SPEC0 = list(),list(),list(),list(),list(),list()\n",
    "    \n",
    "    tn,fp,fn,tp = confusion_matrix_all(data_train,i) \n",
    "    try:\n",
    "        pre = tp/(tp+fp)\n",
    "        re= tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        spec = 1-(tn/(tn+fp))\n",
    "    except ZeroDivisionError:\n",
    "        pre,re,acc,tpr,fpr,spec =1,0,0,0,0,0      \n",
    "            \n",
    "    TP0.append(tp)\n",
    "    TN0.append(tn)\n",
    "    FP0.append(fp)\n",
    "    FN0.append(fn)\n",
    "    precision0.append(pre)\n",
    "    recall0.append(re)\n",
    "    ACC0.append(acc)\n",
    "    TPR0.append(re)\n",
    "    FPR0.append(fpr)       \n",
    "    SPEC0.append(spec)\n",
    "        \n",
    "    precision.append(precision0)\n",
    "    recall.append(recall0)\n",
    "    ACC.append(ACC0)\n",
    "    TPR.append(TPR0)\n",
    "    FPR.append(FPR0)       \n",
    "    SPEC.append(SPEC0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average per threshold \n",
    "precision1,recall1,ACC1,TPR1,FPR1,SPEC1 = list(),list(),list(),list(),list(),list()\n",
    "from statistics import *\n",
    "for m in range(0,len(precision)):\n",
    "    a1 =mean(precision[m])\n",
    "    a2 =mean(recall[m])\n",
    "    a3 =mean(ACC[m])\n",
    "    a4 =mean(TPR[m])\n",
    "    a5 =mean(FPR[m])\n",
    "    a6 =mean(SPEC[m])\n",
    "    \n",
    "    precision1.append(a1)\n",
    "    recall1.append(a2)\n",
    "    ACC1.append(a3)\n",
    "    TPR1.append(a4)\n",
    "    FPR1.append(a5)       \n",
    "    SPEC1.append(a6)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "import numpy as np\n",
    "i = np.arange(len(precision1)) # index for df\n",
    "roc0 = pd.DataFrame({'Threshold' : pd.Series(threshold, index=i),'Precision' : pd.Series(precision1, index = i),'Recall' : pd.Series(recall1, index = i),\n",
    "                     'tpr' : pd.Series(TPR1, index = i),'fpr' : pd.Series(FPR1, index = i),'1-Spec' : pd.Series(SPEC1, index = i),  'ACC' : pd.Series(ACC1, index = i), \n",
    "                     'TN' : pd.Series(TN0, index = i), 'FP' : pd.Series(FP0, index = i), 'FN' : pd.Series(FN0, index = i), 'TP' : pd.Series(TP0, index = i)},)\n",
    "roc0 = roc0.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  sen VS spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sen VS spec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sen= np.array(roc0['tpr'])\n",
    "spec = np.array(roc0['1-Spec'])\n",
    "# from matplotlib import pyplot\n",
    "lw = 3\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.axhline(0, lw=2.5, color='black')\n",
    "plt.axvline(0, lw=2.5, color='black')\n",
    "plt.plot([0, 0],[1, 1],'c', linestyle='--',lw=2.5)\n",
    "plt.plot(spec,sen,'b', marker='.',lw=lw)  \n",
    "    # axis labels\n",
    "plt.xlabel('1-Specificity',fontsize=18)\n",
    "plt.ylabel('Sensitivity',fontsize=18)\n",
    "plt.title('Sensitivity & 1-Specificity',fontsize=20)\n",
    "    # show the legend\n",
    "plt.legend()\n",
    "    # show the plot\n",
    "plt.show()\n",
    "    # calculate the precision-recall auc\n",
    "from sklearn.metrics import auc\n",
    "auc_score = auc(spec, sen)\n",
    "print('PR AUC (area = %0.2f)' % (auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  Precision & Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision & Recall Curve\n",
    "import numpy as np\n",
    "recall = np.array(roc0['Recall'])\n",
    "precision = np.array(roc0['Precision'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "lw = 3\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.axhline(0, lw=2.5, color='black')\n",
    "plt.axvline(0, lw=2.5, color='black')\n",
    "fig.patch.set_facecolor('w')\n",
    "plt.plot([0, 1], [0.5, 0.5],'c', linestyle='--',lw=2.5)\n",
    "pyplot.plot(recall, precision,'b', marker='.', lw=lw)\n",
    "    # axis labels\n",
    "pyplot.xlabel('Recall',fontsize=18)\n",
    "pyplot.ylabel('Precision',fontsize=18)\n",
    "pyplot.title('Precision & Recall',fontsize=20)\n",
    "    # show the legend\n",
    "pyplot.legend()\n",
    "    # show the plot\n",
    "pyplot.show()\n",
    "    # calculate the precision-recall auc\n",
    "from sklearn.metrics import auc\n",
    "auc_score = auc(recall, precision)\n",
    "print('PR AUC (area = %0.2f)' % (auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - create dataframe for Grad CAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง folder เก็บรูป \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "path0 = \"/media/tohn/SSD/image/test_GradCam/B0_val\" \n",
    "\n",
    "try:\n",
    "    os.mkdir(path0)\n",
    "except OSError:\n",
    "    shutil.rmtree(path0)\n",
    "    os.mkdir(path0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง folder เก็บรูป \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "path1 = path0+'/abn_correct/'\n",
    "path2 = path0+'/abn_missing/'\n",
    "path3 = path0+'/Nor_correct/'\n",
    "path4 = path0+'/Nor_missing/'\n",
    "try:\n",
    "    os.mkdir(path1)\n",
    "    os.mkdir(path2)\n",
    "    os.mkdir(path3)\n",
    "    os.mkdir(path4)\n",
    "except OSError:\n",
    "    shutil.rmtree(path1)\n",
    "    shutil.rmtree(path2)\n",
    "    shutil.rmtree(path3)\n",
    "    shutil.rmtree(path4)\n",
    "    os.mkdir(path1)\n",
    "    os.mkdir(path2)\n",
    "    os.mkdir(path3)\n",
    "    os.mkdir(path4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Abnormal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image function\n",
    "def load_image(img_path):\n",
    "    # Read the image and resize it\n",
    "    img = image.load_img(img_path, target_size=(height, width))\n",
    "    # Convert it to a Numpy array with target shape.\n",
    "    x = image.img_to_array(img)\n",
    "    # Reshape\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x /= 255.\n",
    "    return x,img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe\n",
    "abnormal  = df[df['Class']=='Abnormal']\n",
    "ab_correct = abnormal[abnormal['Class']==abnormal['category']] # correct\n",
    "ab_wrong = abnormal[abnormal['Class']!=abnormal['category']]\n",
    "#select position \n",
    "print('abnormal:',len(abnormal))\n",
    "print('ab_correct:',len(ab_correct))\n",
    "print('ab_wrong:',len(ab_wrong))\n",
    "print(len(set(ab_correct['Sub Position'])))\n",
    "print(set(ab_correct['Sub Position']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ab_correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-explain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load only max &min prob of each views(P1,P2,P31,...,P72) *** For correct\n",
    "max_df = list()\n",
    "min_df = list()\n",
    "classs = list(set(ab_correct['Sub Position']))\n",
    "for i in classs:\n",
    "    posi = ab_correct[ab_correct['Sub Position'] == i]\n",
    "    #max\n",
    "    max_prob = posi[posi['Prob'] == posi['Prob'].max()][0:1].reset_index()\n",
    "    SubPosi = i\n",
    "    case = 'ab_correct'\n",
    "    case_prob = 'Max'\n",
    "    prob = max_prob['Prob'].tolist()[0]\n",
    "    path = max_prob['Path Crop'].tolist()[0]\n",
    "\n",
    "    max_df.append({'Sub Position':SubPosi,'Case':case,'Case_prob':case_prob,'Prob':prob,'Path':path})\n",
    "    \n",
    "    #min\n",
    "    min_prob = posi[posi['Prob'] == posi['Prob'].min()][0:1].reset_index()\n",
    "    SubPosi = i\n",
    "    case = 'ab_correct'\n",
    "    case_prob = 'Min'\n",
    "    prob = min_prob['Prob'].tolist()[0]\n",
    "    path = min_prob['Path Crop'].tolist()[0]\n",
    "\n",
    "    min_df.append({'Sub Position':SubPosi,'Case':case,'Case_prob':case_prob,'Prob':prob,'Path':path})\n",
    "tabktdf = pd.DataFrame(max_df+min_df)\n",
    "tabktdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = tabktdf['Path'].tolist()\n",
    "case = tabktdf['Case_prob'].tolist()\n",
    "prob = tabktdf['Prob'].round(4).tolist()\n",
    "imlist = list()\n",
    "idx = range(0,len(img_paths))\n",
    "for i in idx :\n",
    "    j = img_paths[i]\n",
    "    imlist.append(j)\n",
    "    j = j.split('/')[-1]\n",
    "    os.chdir(path1)\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tf_explain.core.grad_cam import GradCAM\n",
    "    explainer = GradCAM()\n",
    "\n",
    "    img,ori = load_image(img_paths[i])\n",
    "    data = (img, None)\n",
    "\n",
    "    grid = explainer.explain(data, model, class_index=0)\n",
    "    \n",
    "    explainer.save(grid,'.',\"ab_cor_\"+str(i)+\"_\"+str(case[i])+\"_\"+str(prob[i])+\"_\"+str(j)+\".png\")\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load USAI image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "# load the image\n",
    "idx = imlist\n",
    "for i in idx :\n",
    "    j = i\n",
    "    j = j.split('/')[-1]\n",
    "    img = image.load_img(i)\n",
    "    os.chdir(path1)\n",
    "    save_img(str(j)+'.png', img)\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ab_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nor_wrong:',len(ab_wrong))\n",
    "w_img_paths = ab_wrong['Path Crop'].tolist()\n",
    "w_prob = ab_wrong['Prob'].round(4).tolist()\n",
    "ab_wrong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = list()\n",
    "idx = range(0,len(w_img_paths))\n",
    "for i in idx :\n",
    "    j = w_img_paths[i]\n",
    "    imlist.append(j)\n",
    "    j = j.split('/')[-1]\n",
    "#     print(j)\n",
    "    os.chdir(path2)\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tf_explain.core.grad_cam import GradCAM\n",
    "    explainer = GradCAM()\n",
    "\n",
    "    img,ori = load_image(w_img_paths[i])\n",
    "    data = (img, None)\n",
    "\n",
    "    grid = explainer.explain(data, model, class_index=0) \n",
    "    explainer.save(grid,'.',\"Nor_missing_\"+str(w_prob[i])+\"_\"+str(j)+\"_\"+str(i)+\".png\")\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Load USAI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "idx = imlist\n",
    "for i in idx :\n",
    "    j = i\n",
    "    j = j.split('/')[-1]\n",
    "    img = image.load_img(i)\n",
    "    os.chdir(path2)\n",
    "    save_img(str(j)+'.png', img)\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Show Correct Abnormal GradCam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "explainer = GradCAM()\n",
    "img,ori = load_image(img_paths[0])\n",
    "data = (img, None)\n",
    "grid = explainer.explain(data, model, class_index=1) \n",
    "explainer.save(grid, \".\", \"grad_cam.png\")\n",
    "print(img_paths[0])\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(img_paths[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Show Miss Abnormal GradCam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "explainer = GradCAM()\n",
    "img,ori = load_image(w_img_paths[0])\n",
    "data = (img, None)\n",
    "grid = explainer.explain(data, model, class_index=1) \n",
    "explainer.save(grid, \".\", \"grad_cam.png\")\n",
    "print(img_paths[0])\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(w_img_paths[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe\n",
    "normal  = df[df['Class']=='Normal']\n",
    "nor_correct = normal[normal['Class']==normal['category']] # correct\n",
    "nor_wrong = normal[normal['Class']!=normal['category']]\n",
    "print('normal:',len(normal))\n",
    "print('nor_correct:',len(nor_correct))\n",
    "print('nor_wrong:',len(nor_wrong))\n",
    "#select position \n",
    "print(len(set(nor_correct['Sub Position'])))\n",
    "print(set(nor_correct['Sub Position']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nor_correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load only max &min prob of each views(P1,P2,P31,...,P72) *** For correct\n",
    "max_df = list()\n",
    "min_df = list()\n",
    "classs = list(set(nor_correct['Sub Position']))\n",
    "for i in classs:\n",
    "    posi = nor_correct[nor_correct['Sub Position'] == i]\n",
    "    #max\n",
    "    max_prob = posi[posi['Prob'] == posi['Prob'].max()][0:1].reset_index()\n",
    "    SubPosi = i\n",
    "    case = 'nor_correct'\n",
    "    case_prob = 'Max'\n",
    "    prob = max_prob['Prob'].tolist()[0]\n",
    "    path = max_prob['Path Crop'].tolist()[0]\n",
    "\n",
    "    max_df.append({'Sub Position':SubPosi,'Case':case,'Case_prob':case_prob,'Prob':prob,'Path':path})\n",
    "    \n",
    "    #min\n",
    "    min_prob = posi[posi['Prob'] == posi['Prob'].min()][0:1].reset_index()\n",
    "    SubPosi = i\n",
    "    case = 'nor_correct'\n",
    "    case_prob = 'Min'\n",
    "    prob = min_prob['Prob'].tolist()[0]\n",
    "    path = min_prob['Path Crop'].tolist()[0]\n",
    "\n",
    "    min_df.append({'Sub Position':SubPosi,'Case':case,'Case_prob':case_prob,'Prob':prob,'Path':path})\n",
    "tabktdf = pd.DataFrame(max_df+min_df)\n",
    "tabktdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Grad Cam image\n",
    "\n",
    "img_paths = tabktdf['Path'].tolist()\n",
    "case = tabktdf['Case_prob'].tolist()\n",
    "prob = tabktdf['Prob'].round(4).tolist()\n",
    "\n",
    "imlist = list()\n",
    "idx = range(0,len(img_paths))\n",
    "for i in idx :\n",
    "    j = img_paths[i]\n",
    "    imlist.append(j)\n",
    "    j = j.split('/')[-1]\n",
    "    os.chdir(path3)\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tf_explain.core.grad_cam import GradCAM\n",
    "    explainer = GradCAM()\n",
    "\n",
    "    img,ori = load_image(img_paths[i])\n",
    "    data = (img, None)\n",
    "\n",
    "    grid = explainer.explain(data, model, class_index=0) \n",
    "    explainer.save(grid,'.',\"nor_cor_\"+str(i)+\"_\"+str(case[i])+\"_\"+str(prob[i])+\"_\"+str(j)+\".png\")\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Load USAI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "# load the image\n",
    "idx = imlist\n",
    "for i in idx :\n",
    "    j = i\n",
    "    j = j.split('/')[-1]\n",
    "    img = image.load_img(i)\n",
    "    os.chdir(path3)\n",
    "    save_img(str(j)+'.png', img)\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nor_wrong:',len(nor_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_img_paths = nor_wrong['Path Crop'].tolist()\n",
    "w_prob = nor_wrong['Prob'].round(4).tolist()\n",
    "nor_wrong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = list()\n",
    "idx = range(0,len(w_img_paths))\n",
    "for i in idx :\n",
    "    j = w_img_paths[i]\n",
    "    imlist.append(j)\n",
    "    j = j.split('/')[-1]\n",
    "#     print(j)\n",
    "    os.chdir(path4)\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tf_explain.core.grad_cam import GradCAM\n",
    "    explainer = GradCAM()\n",
    "\n",
    "    img,ori = load_image(w_img_paths[i])\n",
    "    data = (img, None)\n",
    "\n",
    "    grid = explainer.explain(data, model, class_index=0) \n",
    "    explainer.save(grid,'.',\"Nor_missing_\"+str(w_prob[i])+\"_\"+str(j)+\"_\"+str(i)+\".png\")\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load USAI image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "idx = imlist\n",
    "for i in idx :\n",
    "    j = i\n",
    "    j = j.split('/')[-1]\n",
    "    img = image.load_img(i)\n",
    "    os.chdir(path4)\n",
    "    save_img(str(j)+'.png', img)\n",
    "print(len(imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Show Correct NormalGradCam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "explainer = GradCAM()\n",
    "img,ori = load_image(img_paths[0])\n",
    "data = (img, None)\n",
    "grid = explainer.explain(data, model, class_index=1) \n",
    "explainer.save(grid, \".\", \"grad_cam.png\")\n",
    "print(img_paths[0])\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(img_paths[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Show Miss Normal GradCam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "explainer = GradCAM()\n",
    "img,ori = load_image(w_img_paths[0])\n",
    "data = (img, None)\n",
    "grid = explainer.explain(data, model, class_index=1) \n",
    "explainer.save(grid, \".\", \"grad_cam.png\")\n",
    "print(img_paths[0])\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(w_img_paths[0])\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usai",
   "language": "python",
   "name": "usai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
